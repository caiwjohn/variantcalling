'''
PREAMBLE
    Maybe useful:
        `ls reads | cut -d '_' -f 1 | uniq >> samples.in`

'''
import itertools
import os

configfile: "test.yaml"


# Rule to target full run
rule all:
    input:
        "filtered_vcf/cohort.vcf"

# Trim adapters off single-end reads
rule fastq_trim_pe:
    input:
        fq1 = "../{sample}_1.fastq.gz",
        fq2 = "../{sample}_2.fastq.gz"
    params:
        ref= "adapters"
    threads:8
    output:
        fq1o = 'trimmed_reads/{sample}_1.fastq.gz',
        fq2o = 'trimmed_reads/{sample}_2.fastq.gz'
    benchmark:
        "benchmarks/trim_pe/{sample}.txt"
    shell:
        "bbduk.sh in1={input.fq1} in2={input.fq2} "
        "out1={output.fq1o} out2={output.fq2o} ref={params.ref} "
        "ktrim=r k=25 t={threads}"

rule fastq_trim_se:
    input:
        fq = "../single/{sample}.fastq.gz"
    params:
        ref = "adapters"
    threads:8
    output:
        fqo = "trimmed_reads/{sample}.fastq.gz"
    benchmark:
        "benchmarks/trim_se/{sample}.txt"
    shell:
        "bbduk.sh in={input.fq} "
        "out={output.fqo} ref={params.ref} "
        "ktrim=r k=25 t={threads}"

    # run:
    #     # out1_index = [x for x in output.pe if '_1.fastq' in str(x)]
    #     # out2_index = [x for x in output.pe if '_2.fastq' in str(x)]
    #     input1=str(input.fq1[0])
    #     input2=str(input.fq2[0])
    #     out1=str(output.fq1o[0])
    #     out2=str(output.fq2o[0])
    #     # out1=str(out1_index[0])
    #     # out2=str(out2_index[0])
    #     # print(input1)
    #     # print(input2)
    #     print(out1)
    #     print(out2)
    #     shell("bbduk.sh in1={input.fq1) in2={input2} "
    #               "out1={out1} out2={out2} ref={params.ref} "
    #               "ktrim=r k=25")


# rule fastq_trim_se:
#     input:
#         fq1 = expand(trimmed_reads/)\
# else:
#     shell("bbduk.sh in={input} "
#           "out={output.se} ref= {params.ref} "
#           "ktrim=r k=25")

# Merge paired ends into one read
rule align_ends:
    input:
        lambda wildcards: expand("trimmed_reads/{read}.fastq.gz", read= config["reads"][wildcards.read]["ends"])
    params:
        "Ptrichocarpa_444_v3.0.fa"
    threads:8
    output:
        temp("mapped_reads/{read}.bam")
    benchmark:
        "benchmarks/bwa_mem_sort/{read}.txt"
    shell:
        "bwa mem -t {threads} {params} {input} | "
        "samtools sort -@{threads} -o {output}"

# Merge reads for one sample based on config file
rule merge_sort_bam:
    input:
        lambda wildcards: config["samples"][wildcards.sample]
    threads:8
    output:
        temp("merged_bam/{sample}.bam")
    benchmark:
        "benchmarks/merge/{sample}.txt"
    shell:
        "samtools merge -@ {threads} {output} {input}"

rule read_groups:
        input:
            "merged_bam/{sample}.bam"
        output:
            temp("labeled_bam/{sample}.bam")
        benchmark:
            "benchmarks/add_read_groups/{sample}.txt"
        shell:
            "picard AddOrReplaceReadGroups I={input} "
            "O={output} RGID={wildcards.sample} RGLB=NA "
            "RGPL=illumina RGPU=NA RGSM={wildcards.sample}"

# Marks alleles that may have been falsely amplified during PCR
rule mark_duplicates:
    input:
        "labeled_bam/{sample}.bam"
    threads:8
    output:
        temp("duplicate_marked/{sample}.bam")
    benchmark:
        "benchmarks/mark_duplicates/{sample}.txt"
    shell:
        "sambamba markdup -t {threads} {input} {output}"

## Scott hasn't seen much benefit to recalibrating and BQSR
rule recalibrate:
    input:
        ref= "Ptrichocarpa_444_v3.0.fa",
        reads= "duplicate_marked/{sample}.bam"
    output:
        "recal/{sample}_report.table"
    benchmark:
        "benchmarks/recalibrate/{sample}.txt"
    shell:
        "gatk BaseRecalibrator -R {input.ref} "
        "-I {input.reads} -O {output} --known-sites Chr13_subset_882.vcf"

# Parameterizes to detect false positives
rule BQSR:
    input:
        ref= "Ptrichocarpa_444_v3.0.fa",
        reads= "duplicate_marked/{sample}.bam",
        recal= "recal/{sample}_report.table"
    output:
        temp("recal/{sample}.bam")
    benchmark:
        "benchmarks/bqsr/{sample}.txt"
    shell:
        "gatk ApplyBQSR -R {input.ref} "
        "-I {input.reads} --bqsr-recal-file "
        "{input.recal} -O {output}"

# samtools is faster than HaplotypeCaller
rule haplotype_caller:
    input:
        ref= "Ptrichocarpa_444_v3.0.fa",
        reads= "recal/{sample}.bam"
    threads: 8
    output:
        "GVCF/{sample}.g.vcf"
    benchmark:
        "benchmarks/haplotype_caller/{sample}.txt"
    shell:
        "gatk HaplotypeCaller -R "
        "{input.ref} "
        "-I {input.reads} "
        "--emit-ref-confidence GVCF "
        "--native-pair-hmm-threads {threads} "
        "-O {output}"

#https://bitbucket.org/snakemake/snakemake/issues/895/combine-multiple-files-for-input-but
rule consolidate_gvcf:
    input:
        expand("GVCF/{sample}.g.vcf", sample= config['samples'])
    params:
        # ref = "Ptrichocarpa_444_v3.0.bed"
        lambda wildcards, input: " -V ".join(input)
    output:
        directory("cohort_database")
    shell:
        "gatk GenomicsDBImport "
        "--genomicsdb-workspace-path {output} "
        "--batch-size 50 -L Ptrichocarpa_444_v3.0.bed "
        "-V {params} "
        "--reader-threads 5"

rule genotype_gvcf:
    input:
        ref= "Ptrichocarpa_444_v3.0.fa",
        db= "cohort_database"
    output:
        "unfiltered_vcf/cohort.vcf"
    shell:
        "gatk GenotypeGVCFs -R {input.ref} "
        "-V {input.db} "
        "-newQual -O {output}"

#TODO: insert quality filters flag
rule filter_vcf:
    input:
        "unfiltered_vcf/cohort.vcf"
    output:
        "filtered_vcf/cohort.vcf"
    shell:
        "picard FilterVcf -I {input} "
        "-O {output} "
        "-[insert quality filters here]"
